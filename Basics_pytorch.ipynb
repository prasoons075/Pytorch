{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRxNcEA-pUbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8djpqxr5vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bc04a3de-0790-4ee1-8aac-aca4166f8bee"
      },
      "source": [
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "y = np.empty(1)\n",
        "print(x)\n",
        "print(y)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "y = np.empty(3)\n",
        "print(x)\n",
        "print(y)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "y = np.empty((2,3))\n",
        "print(x)\n",
        "print(y)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.1531e-35])\n",
            "[9.]\n",
            "tensor([1.1531e-35, 0.0000e+00, 5.0447e-44])\n",
            "[0.75 0.75 0.  ]\n",
            "tensor([[1.1531e-35, 0.0000e+00, 4.2039e-45],\n",
            "        [0.0000e+00, 1.4013e-45, 0.0000e+00]])\n",
            "[[4.52465793e-316 1.13635099e-322 2.12199579e-314]\n",
            " [8.81941692e+247 7.36093992e+223 1.81844573e-306]]\n",
            "tensor([[[1.1531e-35, 0.0000e+00, 8.4078e-45],\n",
            "         [0.0000e+00, 1.4013e-45, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WVhp_t2sBJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5adbcf29-97e4-4285-c036-8221a07ed297"
      },
      "source": [
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "y = np.random.rand(5,3)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4411, 0.8574, 0.7882],\n",
            "        [0.3418, 0.7050, 0.8734],\n",
            "        [0.6362, 0.6112, 0.3384],\n",
            "        [0.0651, 0.9969, 0.2283],\n",
            "        [0.4568, 0.5402, 0.8449]])\n",
            "[[0.44578847 0.55372383 0.76882134]\n",
            " [0.37838128 0.43534708 0.25734019]\n",
            " [0.007463   0.61861402 0.75599084]\n",
            " [0.88981829 0.95707311 0.95371256]\n",
            " [0.25153734 0.88088372 0.59379655]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBz4powrs2tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "31fd318e-0941-410f-b0b3-77cdbcf642fb"
      },
      "source": [
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su4yxHF6tpOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e596dad-31ae-4b15-f858-86b05807cb77"
      },
      "source": [
        "# check size\n",
        "print(x.size())\n",
        "# check data type\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afdLv2nStvxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b17ad436-7510-4e66-e67b-6ab2b8045844"
      },
      "source": [
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gku-Y0xt0gM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5292957b-d265-4d02-f304-d80a9f029e72"
      },
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpljSMR6t8JA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "144c13d9-880f-4cc0-bc3b-5acf06ff7c6e"
      },
      "source": [
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIB4-JIAuh1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3cdf84d5-270e-49d8-ef5d-7ec6d6d5bc82"
      },
      "source": [
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhQmxCgMuj-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "99cf6675-2d4d-4e3d-cffa-2355ceb6d8ff"
      },
      "source": [
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F522yFLtu377",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sac53nrkvPoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d6f0d8a4-83d5-4521-885e-7f00ff8b4e34"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z = x + y\n",
        "print(z)\n",
        "z = torch.add(x,y)\n",
        "print(z)\n",
        "y.add(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8683, 0.0600],\n",
            "        [0.1364, 0.5356]])\n",
            "tensor([[0.7748, 0.0649],\n",
            "        [0.0731, 0.5220]])\n",
            "tensor([[1.6430, 0.1250],\n",
            "        [0.2095, 1.0576]])\n",
            "tensor([[1.6430, 0.1250],\n",
            "        [0.2095, 1.0576]])\n",
            "tensor([[0.7748, 0.0649],\n",
            "        [0.0731, 0.5220]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StZ4tQe9vQxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4903cbc2-5b73-4a2a-ddbe-083ea6279592"
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[1,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0304, 0.7748, 0.8352],\n",
            "        [0.3022, 0.4790, 0.1672],\n",
            "        [0.0235, 0.8304, 0.1735],\n",
            "        [0.6525, 0.7849, 0.4395],\n",
            "        [0.0192, 0.4524, 0.1174]])\n",
            "tensor([0.3022, 0.4790, 0.1672])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAP5ZoNQw_tK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3c7ad54-614e-4e86-c27c-baefc3fb3be5"
      },
      "source": [
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 2)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([8, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH7BNj2rx1vo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "78937266-a071-4245-eb55-1233a538fb38"
      },
      "source": [
        "## autograd and gradients\n",
        "# The autograd package provides automatic differentiation \n",
        "# for all operations on Tensors\n",
        "# requires_grad = True -> tracks all operations on the tensor. \n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.5510, -1.2571, -0.6856], requires_grad=True)\n",
            "tensor([0.4490, 0.7429, 1.3144], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f6b140da908>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmLqM0HpzRzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a555fab5-d4ea-42f2-d033-863098ea98c7"
      },
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6049, 1.6559, 5.1826], grad_fn=<MulBackward0>)\n",
            "tensor(2.4811, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmVxE2-FzpM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0291aeeb-920c-4443-bcb1-56a097272314"
      },
      "source": [
        "# to calculate gradients\n",
        "z.backward()  #dz/dx\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.8981, 1.4859, 2.6287])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83m9UKjxz5u7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fd549ed7-53d4-40f5-a084-41de3b9abe6a"
      },
      "source": [
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    \n",
        "    print(weights.grad)\n",
        "\n",
        "    # # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlz02191_ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlwXqIq520ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c430db46-3b5b-463d-dc33-2d9a8f052267"
      },
      "source": [
        "# Back Propogation\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxU_KI5_5vA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c19ef61c-5ccd-4995-b8b8-88ce367463ec"
      },
      "source": [
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqTLemdk5xpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute every step manually for backpropagation\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.dot(2*x, y_pred - y).mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcdXZ2NG6Mi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2af0909d-d7aa-498a-b963-7ea84397e475"
      },
      "source": [
        "print(f'Prediction before training: f(6) = {forward(6):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 15\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "    \n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "     \n",
        "print(f'Prediction after training: f(6) = {forward(6):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training: f(6) = 11.999\n",
            "epoch 1: w = 2.000, loss = 0.00000033\n",
            "epoch 3: w = 2.000, loss = 0.00000001\n",
            "epoch 5: w = 2.000, loss = 0.00000000\n",
            "epoch 7: w = 2.000, loss = 0.00000000\n",
            "epoch 9: w = 2.000, loss = 0.00000000\n",
            "epoch 11: w = 2.000, loss = 0.00000000\n",
            "epoch 13: w = 2.000, loss = 0.00000000\n",
            "epoch 15: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(6) = 12.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqGVyt8a6TPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ddee41ba-e2ee-4728-d8b2-a02913cfa6ce"
      },
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = 5.192\n",
            "epoch  1 : w =  0.9910392165184021  loss =  tensor(5.4881, grad_fn=<MeanBackward0>)\n",
            "epoch  11 : w =  1.5283622741699219  loss =  tensor(0.3362, grad_fn=<MeanBackward0>)\n",
            "epoch  21 : w =  1.6239278316497803  loss =  tensor(0.1916, grad_fn=<MeanBackward0>)\n",
            "epoch  31 : w =  1.648167371749878  loss =  tensor(0.1772, grad_fn=<MeanBackward0>)\n",
            "epoch  41 : w =  1.6606721878051758  loss =  tensor(0.1668, grad_fn=<MeanBackward0>)\n",
            "epoch  51 : w =  1.6710351705551147  loss =  tensor(0.1571, grad_fn=<MeanBackward0>)\n",
            "epoch  61 : w =  1.680807113647461  loss =  tensor(0.1480, grad_fn=<MeanBackward0>)\n",
            "epoch  71 : w =  1.6902445554733276  loss =  tensor(0.1394, grad_fn=<MeanBackward0>)\n",
            "epoch  81 : w =  1.699395775794983  loss =  tensor(0.1312, grad_fn=<MeanBackward0>)\n",
            "epoch  91 : w =  1.708275556564331  loss =  tensor(0.1236, grad_fn=<MeanBackward0>)\n",
            "Prediction after training: f(5) = 9.415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etdDSMOi9kYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}